{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mushrooms_data\n",
    "import cars_data\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and formating datasets\n",
    "Random Forest needs data and target separatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_to_number(data):\n",
    "    dictionary = {}\n",
    "    for column in data.columns:\n",
    "        dictionary[column] = {}\n",
    "        corresponding_number = 0\n",
    "        checked = []\n",
    "        for value in data[column]:\n",
    "            if value not in checked:\n",
    "                checked.append(value)\n",
    "                dictionary[column][value] = corresponding_number\n",
    "                corresponding_number += 1\n",
    "    return data.replace(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset):\n",
    "    complete_data = get_values_to_number(dataset.get_data())\n",
    "    data = complete_data.drop(['label'], axis=1).values.tolist()\n",
    "    shuffle(data)\n",
    "    targets = complete_data['label'].values.tolist()\n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_and_test_sets(data, targets, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=test_size, random_state=1)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1210\n",
       "1     384\n",
       "3      69\n",
       "2      65\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(targets).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    950\n",
       "1    325\n",
       "3     55\n",
       "2     52\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    260\n",
       "1     59\n",
       "3     14\n",
       "2     13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and get the scores using Random Forest and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In random forests, each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features. As a result of this randomness, the bias of the forest usually slightly increases (with respect to the bias of a single non-random tree) but, due to averaging, its variance also decreases, usually more than compensating for the increase in bias, hence yielding an overall better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters to test\n",
    "--> Random Forest\n",
    "\n",
    "- n_estimators - integer, optional (default=10): number of trees in the forest.\n",
    "\n",
    "- criterion - string, optional (default=”gini”): The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n",
    "\n",
    "- max_features - int, float, string or None, optional (default=”auto”): number of features to consider when looking for the best split:\n",
    "\n",
    "        If int, then consider max_features features at each split.\n",
    "        If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split.\n",
    "        If “auto”, then max_features=sqrt(n_features).\n",
    "        If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "        If “log2”, then max_features=log2(n_features).\n",
    "        If None, then max_features=n_features.\n",
    "\n",
    "    Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.\n",
    "    \n",
    "--> Cross-validation\n",
    "\n",
    "- cv : int, cross-validation generator or an iterable, optional\n",
    "\n",
    "    Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
    "\n",
    "            None, to use the default 3-fold cross validation,\n",
    "            integer, to specify the number of folds in a (Stratified)KFold,\n",
    "            An object to be used as a cross-validation generator.\n",
    "            An iterable yielding train, test splits.\n",
    "            \n",
    "- scoring: ‘accuracy’, ‘average_precision’, ‘f1’, ‘precision’, ‘recall’\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mushrooms dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=45, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, targets = get_data(mushrooms_data)\n",
    "X_train, X_test, y_train, y_test = create_train_and_test_sets(data, targets)\n",
    "clf = RandomForestClassifier()\n",
    "# parameters = {'n_estimators': [5, 10, 20, 40, 100], 'criterion': ['gini','entropy']}\n",
    "#                               [30,40,50]              --> 40 de novo\n",
    "#                               [35,40,45]              --> 45\n",
    "#                               [42,45,47]              --> 45\n",
    "#                               [100,200,300]           --> 200\n",
    "#                               [150,200,500]           --> 500\n",
    "#                               [5,50,100,300,500,1000] --> 50\n",
    "#                               [40,50,200,500,1000]    --> 200\n",
    "# RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            #max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            #min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            #min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            #n_estimators=40, n_jobs=1, oob_score=False, random_state=None,\n",
    "            #verbose=0, warm_start=False)\n",
    "parameters = {'n_estimators': [45]}\n",
    "clf = GridSearchCV(clf, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50830769230769235"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[372, 433],\n",
       "       [366, 454]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51845018,  0.50523077,  0.49046154,  0.52278325,  0.48460591])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, data, targets, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cars dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = get_data(cars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=60, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = create_train_and_test_sets(data, targets)\n",
    "clf = RandomForestClassifier()\n",
    "# parameters = {'n_estimators': [10,50,100,200,500,1000], 'criterion': ['gini','entropy']}\n",
    "#                               [75,100,150]        --> 75\n",
    "#                               [60,70,80]          --> 60\n",
    "#                               [50,60,70]          --> 60\n",
    "# RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            #max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            #min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            #min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            #n_estimators=40, n_jobs=1, oob_score=False, random_state=None,\n",
    "            #verbose=0, warm_start=False)\n",
    "parameters = {'n_estimators': [60], 'criterion': ['gini','entropy']}\n",
    "clf = GridSearchCV(clf, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70231213872832365"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[239,  19,   1,   1],\n",
       "       [ 55,   4,   0,   0],\n",
       "       [ 13,   0,   0,   0],\n",
       "       [ 13,   1,   0,   0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
